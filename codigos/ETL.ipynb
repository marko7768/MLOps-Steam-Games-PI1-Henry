{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import ast\n",
    "import re\n",
    "from datetime import datetime\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ETL steam games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steam_games_ruta = 'datos/output_steam_games.json'\n",
    "\n",
    "# El json se va a leer linea por linea \n",
    "filas_json = []\n",
    "with open(steam_games_ruta) as f:\n",
    "    for line in f.readlines():\n",
    "        data = json.loads(line)\n",
    "        filas_json.append(data)\n",
    "\n",
    "# Se almacena en un data frame de pandas\n",
    "df_games = pd.DataFrame(filas_json)\n",
    "df_games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se cambia el tipo de dato de string a bool\n",
    "df_games['early_access'] = df_games['early_access'].astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se cambia el tipo de dato de string a flotante y se asigna cero para los casos especiales\n",
    "df_games['price'] = df_games['price'].apply(lambda x: round(float(x), 3) if str(x).replace('.', '', 1).isdigit() else 0).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_games = df_games.explode('genres')\n",
    "df_games = df_games.dropna(subset=['genres'])\n",
    "df_games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_games.shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_games = df_games.drop(['specs', 'url', 'reviews_url','tags'], axis=1)\n",
    "df_games.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   se observa tipo de dato y valores unicos de price\n",
    "print(df_games['release_date'].dtype)\n",
    "print(\"---\"*10)\n",
    "df_games['release_date'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asumiendo que la columna 'release_date' es del formato 'yyyy-mm-dd'\n",
    "df_games['release_year'] = df_games['release_date'].apply(lambda x: x.split('-')[0])\n",
    "\n",
    "# Ahora, 'release_year' contiene solo el año y se elimina la columna 'release_date'\n",
    "df_games.drop(columns=['release_date'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_games['release_year'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define una función lambda para extraer el año si el valor contiene las primeras tres letras de un mes\n",
    "def extract_year(value):\n",
    "    try:\n",
    "        # Si el valor se puede dividir en partes y la última parte es un año, se devuelve\n",
    "        parts = value.split()\n",
    "        last_part = parts[-1]\n",
    "        if last_part.isdigit() and len(last_part) == 4:\n",
    "            return last_part\n",
    "    except:\n",
    "        pass\n",
    "    return pd.NA\n",
    "\n",
    "# Reemplaza \"SOON\" y \"SOON™\" con \"Not-Released-Yet\"\n",
    "df_games['release_year'] = df_games['release_year'].replace(['SOON', 'SOON™'], 'Not-Released-Yet')\n",
    "\n",
    "# Aplica la función lambda a la columna 'release_year'\n",
    "df_games['release_year'] = df_games['release_year'].apply(extract_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lo exporto como csv\n",
    "ruta_df_clean = 'datos/steam_games_clean.csv'\n",
    "df_games.to_csv(ruta_df_clean, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ETL user items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_items_ruta = 'datos/australian_users_items.json'\n",
    "\n",
    "# Lista para almacenar los diccionarios JSON de cada línea\n",
    "data_list = []\n",
    "\n",
    "# Abrir el archivo y procesar cada línea\n",
    "with open(user_items_ruta, 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        try:\n",
    "            # Usar ast.literal_eval para convertir la línea en un diccionario\n",
    "            json_data = ast.literal_eval(line)\n",
    "            data_list.append(json_data)\n",
    "        except ValueError as e:\n",
    "            print(f\"Error en la línea: {line}\")\n",
    "            continue\n",
    "\n",
    "# Crear un DataFrame a partir de la lista de diccionarios\n",
    "df_items = pd.DataFrame(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_items.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se normaliza items\n",
    "df_items = pd.json_normalize(data_list, record_path=['items'], meta=['steam_id','items_count','user_id', 'user_url'] )\n",
    "df_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se proceden a eliminar los duplicados manteniendo el primero\n",
    "df_items = df_items.drop_duplicates(keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#borro la columna playtime_2weeks porque no es necesaria en la api\n",
    "df_items = df_items.drop('playtime_2weeks', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_items.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lo exporto como csv\n",
    "items_clean_ruta = 'datos/user_items_clean.csv'\n",
    "df_items.to_csv(items_clean_ruta, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ETL reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_reviews_ruta = 'datos/australian_user_reviews.json'\n",
    "\n",
    "# Lista para almacenar los diccionarios JSON de cada línea\n",
    "data_list = []\n",
    "\n",
    "# Abrir el archivo y procesar cada línea\n",
    "with open(user_reviews_ruta, 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        try:\n",
    "            # Usar ast.literal_eval para convertir la línea en un diccionario\n",
    "            json_data = ast.literal_eval(line)\n",
    "            data_list.append(json_data)\n",
    "        except ValueError as e:\n",
    "            print(f\"Error en la línea: {line}\")\n",
    "            continue\n",
    "\n",
    "# Crear un DataFrame a partir de la lista de diccionarios\n",
    "df_reviews = pd.DataFrame(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se procede a eliminar duplicados dejando el primer review\n",
    "df_reviews = df_reviews.drop_duplicates(subset='user_id', keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se transforma el json a un formato tabular en columnas\n",
    "df_reviews_norm = pd.json_normalize(df_reviews['reviews'])\n",
    "df_reviews_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se concatenan las columnas que se perdieron\n",
    "df_reviews_norm = pd.concat([df_reviews[['user_id', 'user_url']], df_reviews_norm], axis=1)\n",
    "df_reviews_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
